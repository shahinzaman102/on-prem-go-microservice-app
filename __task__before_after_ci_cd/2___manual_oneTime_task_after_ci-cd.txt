Manual one time Task after ci/cd:
=================================

---Check all the built Docker images by the CI/CD in the Local Minikube Environment

    - Use the below commands ğŸ¡ª 
        minikube ssh
        docker images

---Check the current Kubernetes context in Terminal ğŸ¡ª kubectl config current-context

    We should see "minikube" - means weâ€™re on the correct context.
    Note: If multiple kubernetes contexts are configured, and we need to switch to "minikube" context then ğŸ¡ª 
            - First, list all available Kubernetes contexts ğŸ¡ª kubectl config get-contexts
            - Then, switch to the "minikube" context using ğŸ¡ª kubectl config use-context minikube

---Checking & Validating the app resources

    - Using Terminal (will just check the main resources using Terminal commands) ğŸ¡ª 
        kubectl get svc    kubectl get pods    kubectl get ing
    
    - Using the Dashboard ğŸ¡ª 
        minikube addons enable dashboard
        minikube dashboard  [This will Trigger and auto open the dashboard on a new browser tab]
        
        Note: Keep this terminal session open as long as we want the Kubernetes dashboard to stay active.
    
---Accessing & Testing the App Locally

    - First Update the Local Server's Host file before accessing the app
        - Find the "Private_IP_of_App_Server" using the command ğŸ¡ª minikube ip
        - Then, open Host file with nano, using the command ğŸ¡ª sudo nano /etc/hosts
        - Then, update the Host file like below ğŸ¡ª 

            <Private_IP_of_App_Server> registered_root_domain   ğŸ¡ª  e.g. 192.168.49.2 microsvc.net
            
            Note: we can also use an unregistered_domain (e.g. microsvc.test) while testing with insecure connection (http)
            
            Now, Save the file with Ctrl + o, press Enter, then exit with Ctrl + x.

    - Now, Access the app's domain using Server's Local Browser with insecure http connection e.g. http://microsvc.net
    - Test the functionalities - all should be ok..
    - We can also access [as we deployed the k8s configs] : Postgres UI, MongoDB UI, RabbitMQ UI, MailHog UI - 
      and also test the app's "live-logs" - according to the section ğŸ¡ª 10. Testing the Application from Browser & Terminal - 
      [listed in the project file named ğŸ¡ª "go-microservice-app-gcp/__task__before_after_ci_cd/9___manual_oneTime_task_after_ci-cd.txt"].

---Installing & Validating HPA 

  - Set the config-folder path like this ğŸ¡ª cd /home/shahinzaman/Documents/projects/on-prem-go-microservice-app/config
  - Then run ğŸ¡ª kubectl apply -f hpa-config.yml
  - Check the status ğŸ¡ª kubectl get hpa
  - Validate : 
    - Apply some load from the client [For this, we can use the Test Auth button, since it triggers - 
      a relatively heavier containerâ€”making it easier to generate noticeable load quickly.]
    - Then, monitor the hpa from Terminal ğŸ¡ª 
        kubectl get hpa
        kubectl get pods

--- Enable Metrics Server Before Deploying the Monitoring Stack

    - Enable the minikube add-on ğŸ¡ª minikube addons enable metrics-server
    - Check the enabled add-on list to ensure ğŸ¡ª minikube addons list
    - Check the status of the pods for metrics server ğŸ¡ª kubectl -n kube-system get pods | grep metrics
        - it should show the status of pod ğŸ¡ª 0/1 pod running  [which means there's an issue..]
    - Fix the issue :  
    - First change the default editor to use â€œnanoâ€ for kubectl, using command ğŸ¡ª export KUBE_EDITOR=nano
    - Now, Edit the deployment file using nano ğŸ¡ª kubectl -n kube-system edit deployment metrics-server
    - Now, to the containers block, add this new argument "- --kubelet-insecure-tls" as like below ğŸ¡ª 
        
        containers:
        - name: metrics-server
            args:
            - --cert-dir=/tmp
            - --secure-port=4443
            - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
            - --kubelet-insecure-tls

    - Now, Save the file with Ctrl + o, press Enter, then exit with Ctrl + x.
    - Now, restart metrics server deployment to apply the changes ğŸ¡ª kubectl -n kube-system rollout restart deployment metrics-server
    - Now, check the status ğŸ¡ª kubectl -n kube-system get pods | grep metrics
        - The Status should show 1/1 pod running. Means the metrics server is running & functioning properly.
    - Now, we can check our Server's resource usage status as well with below commands :  
        kubectl top nodes ğŸ¡ª shows the overall CPU and memory usage of the node running our cluster.
        kubectl top pods ğŸ¡ª displays the CPU and memory usage for each running pod associated with our application.

    Now that our Metrics Server is functioning properly, we can finally move forward with deploying our monitoring stack..

---Deploying the Monitoring Stack

    - First Ensure python3 is there [python3 comes pre-installed with Ubuntu LTS], using command ğŸ¡ª python3 --version
    - Now, run the python file "1_install_prometheus_grafana.py" according to it's heading section..
        - Check the status ğŸ¡ª kubectl get all -n monitoring   [all pods should run without any issue]
    - Now, deploy the service monitors for the Monitoring Stack ğŸ¡ª 
        - First set the config folder path. Ex. command: cd /home/shahinzaman/Documents/projects/on-prem-go-microservice-app/config 
        - Now deploy the service monitors ğŸ¡ª kubectl apply -f service-monitor-config.yml
            - Check the status ğŸ¡ª kubectl get servicemonitors   [they should be listed if they are created]

---Accessing & Testing the Monitoring Stack Locally

    - First Update the Local Server's Host file before accessing the Monitoring stack
        - Find the "Private_IP_of_App_Server" using the command ğŸ¡ª minikube ip
        - Then, open Host file with nano, using the command ğŸ¡ª sudo nano /etc/hosts
        - Then, update the Host file like below ğŸ¡ª 

            <Private_IP_of_App_Server> registered_root_domain     ğŸ¡ª  e.g. 192.168.49.2 microsvc.net
            <Private_IP_of_App_Server> subdomain_for_prometheus   ğŸ¡ª  e.g. 192.168.49.2 prometheus.microsvc.net
            <Private_IP_of_App_Server> subdomain_for_grafana      ğŸ¡ª  e.g. 192.168.49.2 grafana.microsvc.net
            
            Note: we can also use an unregistered_domain & subdomains (e.g. microsvc.test, prometheus.microsvc.net, - 
                    grafana.microsvc.net) while testing with insecure connection (http)
            
            Now, Save the file with Ctrl + o, press Enter, then exit with Ctrl + x.

    - Now, Access the subdomains (for prometheus & grafana) using Server's Local Browser with insecure http connection - 
      e.g. http://prometheus.microsvc.net, http://grafana.microsvc.net [for grafana ğŸ¡ª username: admin, password: prom-operator]
    
    - Test the functionalities like ğŸ¡ª 
        - In prometheus : servicemonitors are up or not [this ensures prometheus is scrapping metrics correctly]
        - In grafana: All the default dashboards & custom dashboards (after importing from : config/helm-monitoring-chart/file/..) - 
          are instrumenting dashboard properly. And after configuring the alerting is working properly along with Slack.
        
        For this we can follow the detailed guide from the sections ğŸ¡ª 
            12. Testing the Monitoring stack from Browser
            13. Setting up notification channel for Grafana to receive alerts from Dashboards
            14. Creating Alerting Rule in a Grafana Dashboard
        [listed in the project file named ğŸ¡ª "go-microservice-app-gcp/__task__before_after_ci_cd/9___manual_oneTime_task_after_ci-cd.txt"].

---Expose App Securely to Internet via Cloudflare

    - Install cloudflared:
        install cloudflared via the Cloudflare Package Repository ğŸ¡ª 
            https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/
        Debian Based Distribution (Recommended) ğŸ¡ª https://pkg.cloudflare.com/index.html

        cloudflared version

    - Domain Provider (for our case: SqureSpace Domains) ğŸ¡ª DNS ğŸ¡ª DNS Settings ğŸ¡ª Ensure there's "No custom records"
        This is important because we'll have add custom records to Cloudflare and have to use DNS servers which they preferred.

    - Access the Local Server's Host file ğŸ¡ª command: sudo nano /etc/hosts ğŸ¡ª Ensure there's "No custom records" 
	  [means we've to remove the records which we've added so far for main-domain & sub-domains with Private_IP_of_App_Server]
        This is important because the custom host entry bypasses DNS resolution. If we leave it, the browser will keep - 
        resolving the domain to the local IP address directly, skipping Cloudflare â€” which means we wonâ€™t be able to verify - 
        whether the HTTPS connection is working properly through Cloudflareâ€™s secure tunnel.

    - Cloudflare : https://www.cloudflare.com/ ğŸ¡ª Start for free ğŸ¡ª 
        - Account Home ğŸ¡ª 
            - Add a domain ğŸ¡ª 
                - Ensure the default selection : Quick scan for DNS records
                - Enter an existing domain : microsvc.net
                - Continue
                - Select a plan for microsvc.net
                - Free : Select plan
                - Continue to activation ğŸ¡ª Confirm
            - Last step: Update your nameservers to activate Cloudflare ğŸ¡ª Follow the instructions... ğŸ¡ª Continue
            
            Now, We should receive an Email once our Domain is activated - we should receive it usually within a minute - 
            if it's not then it then it can take more maximum up to 24 hours.

            - To check the status of the Activation ğŸ¡ª 
                Overview ğŸ¡ª it'll show the status Active along side with the domain name
                Account Home ğŸ¡ª it'll show the status Active along side with the domain name
            - To check the applied SSL/TLS certificate ğŸ¡ª 
                Account Home ğŸ¡ª go for the domain overview ğŸ¡ª SSL/TLS - Note: This Certificate will be valid for all the sub-domains also..
            - To validate the Domain's Global availability & it's Applied NameServers ğŸ¡ª 
                https://dnschecker.org/all-dns-records-of-domain.php

        - Now, Login to Cloudflare using Server's integrated Terminal ğŸ¡ª cloudflared login
            On the form of "Authorize Cloudflare Tunnel" ğŸ¡ª Click anywhere on the row containing the Domain listing ğŸ¡ª Authorize

            - If there's any "Authentication Error" - Fix that by : 
                Backup or delete your current cert file ğŸ¡ª 
                    mv ~/.cloudflared/cert.pem ~/.cloudflared/cert.pem.bak
                Re-login ğŸ¡ª 
                    cloudflared login

        - Now, Add the Required CNAME DNS Records for the added Domain in Cloudflare ğŸ¡ª 

            cloudflared tunnel route dns microsvc-tunnel microsvc.net
            cloudflared tunnel route dns microsvc-tunnel broker.microsvc.net
            cloudflared tunnel route dns microsvc-tunnel www.microsvc.net
            cloudflared tunnel route dns microsvc-tunnel prometheus.microsvc.net
            cloudflared tunnel route dns microsvc-tunnel grafana.microsvc.net

            - If there's any failed attempt like ğŸ¡ª "Failed to add route: code: 1003, reason: Failed to create record microsvc.net" :
                Cloudflare : Account Home ğŸ¡ª click on the Domain ğŸ¡ª Overview ğŸ¡ª DNS ğŸ¡ª Records ğŸ¡ª Select the existing Old Record ğŸ¡ª Delete

        - Find the "Private_IP_of_App_Server" using the command ğŸ¡ª minikube ip  [let's assume the Private_IP_of_App_Server is ğŸ¡ª 192.168.49.2]
        - Then, create the Cloudflared configuration directory ğŸ¡ª sudo mkdir -p /etc/cloudflared
        - Now, update the Cloudflared configuration file ğŸ¡ª sudo nano /etc/cloudflared/config.yml
            
            - The final updated config file content should look like below ğŸ¡ª 

                tunnel: microsvc-tunnel
                credentials-file: /home/shahinzaman/.cloudflared/e5df3d73-e595-4bf5-827c-d385df3d4da4.json

                ingress:
                - hostname: microsvc.net
                    service: http://192.168.49.2
                - hostname: broker.microsvc.net
                    service: http://192.168.49.2
                - hostname: www.microsvc.net
                    service: http://192.168.49.2
                - hostname: prometheus.microsvc.net
                    service: http://192.168.49.2
                - hostname: grafana.microsvc.net
                    service: http://192.168.49.2
                - service: http_status:404
        
        - Add a Redirect rule in Cloudflare to Redirect from WWW to Root

            - Cloudflare : Account Home ğŸ¡ª Overview ğŸ¡ª Rules ğŸ¡ª Overview ğŸ¡ª 
                           Templates (from right) ğŸ¡ª Redirect from WWW to Root : [Create a Rule] ğŸ¡ª 

            - Then, Fill form like below ğŸ¡ª 

            - Rule name : Redirect www to root
            - Request URL : https://www.microsvc.net/*
            - Target URL : https://microsvc.net/${1}
                            ${1} preserves the path after the slash
            - Status code: 301
            - Preserve query string (checked)
            - Deploy

        - Start Tunnel ğŸ¡ª cloudflared tunnel run microsvc-tunnel

          Note: Keep this terminal session running to keep the appâ€™s domain accessible via Cloudflare.

---Accessing & Testing the App & Monitoring Stack with Secure HTTPS Connection 
    - Now, Access the app's domain using secure https connection e.g. microsvc.net ğŸ¡ª should be redirected to ğŸ¡ª https://microsvc.net
    - Test the functionalities - all should be ok..
    - And we can also perform & test all the development related task which we performed & test with our insecure http connection.

    - Now, check Redirect from WWW to Root ğŸ¡ª www.microsvc.net ğŸ¡ª should be redirected to ğŸ¡ª https://microsvc.net

    - Now, Access the monitoring stack with the subdomains (for prometheus & grafana) using secure https connection - 
        e.g. prometheus.microsvc.net ğŸ¡ª should be redirected to ğŸ¡ª https://prometheus.microsvc.net, 
        and  grafana.microsvc.net ğŸ¡ª should be redirected to ğŸ¡ª https://grafana.microsvc.net  
                                                                  [for grafana ğŸ¡ª username: admin, password: prom-operator]
    - Now, Test the functionalities with prometheus & grafana like we did before with the insecure http connection. [all should be ok..]

---Explore Key Cloudflare Features Securing Our App along with the secure Tunnel [which are included in our free plan..]
    - Cloudflare : Account Home ğŸ¡ª go for the domain overview ğŸ¡ª Security ğŸ¡ª Settings : 
      at there we'll see the below security modules which are securing our App's Domain ğŸ¡ª 

- Web application exploits â†’ This module will prevent our app from the newest threats out there on the Internet. [Automatically Enabled]
- DDoS attacks â†’ This module will prevent our app from DDoS attacks across the network and application layers automatically. [Automatically Enabled]
- Bot traffic â†’ This module will protect our domain from bad bots, including scraping and form spam. [Need configuration to Enable]
- API abuse â†’ This module will secure our API endpoints. [Automatically Enabled]
- Client-side abuse â†’ This module will keep track of our applicationâ€™s Javascript dependencies and will notify us about any malicious scripts. [Need configuration to Enable]


===============================================================================================================

Destroying the Resources created so far on our Local PC
--------------------------------------------------------

- Delete the minikube environment ğŸ¡ª 

    minikube stop
    minikube delete
    rm -rf ~/.minikube

    minikube status
    
    Note: This will also remove the entire Kubernetes cluster along with all the application resources within it.
          Means it will remove the whole Minikube Environment ğŸ¡ª which includes (Kubernetes cluster and app resources
          within it and also all the built images within it which were created during the ci/cd pipeline run.)

- Delete the built docker images outside of the minikube environment ğŸ¡ª 

	docker image prune -a
    docker images

- Uninstall minikube ğŸ¡ª 
	
    sudo rm /usr/local/bin/minikube
	rm -rf ~/.minikube
	rm -rf ~/.kube  # Only if you're sure you don't need Kubernetes configs (e.g., from other clusters)
	hash -r
	
    minikube version

- Uninstall Docker Engine ğŸ¡ª
	
    sudo apt-get purge -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
	sudo rm /etc/apt/sources.list.d/docker.list
	sudo rm -rf /var/lib/docker
	sudo rm -rf /var/lib/containerd
	sudo apt-get update

	docker version

- Uninstall kubectl ğŸ¡ª 

	sudo rm /usr/local/bin/kubectl
	rm -f ~/kubectl ~/kubectl.sha256
	hash -r
	
	kubectl version --client

- Uninstall GitLab Runner ğŸ¡ª 

	sudo gitlab-runner stop
	sudo gitlab-runner uninstall

	sudo gitlab-runner unregister --all-runners
	
	Check the status of gitlab-runner ğŸ¡ª 
		sudo nano /etc/gitlab-runner/config.toml
		gitlab-runner verify
	
	sudo rm -f /usr/local/bin/gitlab-runner
	sudo rm -rf /etc/gitlab-runner
	sudo rm -rf ~/.gitlab-runner

- Uninstall Cloudflare ğŸ¡ª 

    # Uninstall the package and repo
    sudo apt-get remove --purge cloudflared
    sudo rm /etc/apt/sources.list.d/cloudflared.list
    sudo rm /usr/share/keyrings/cloudflare-main.gpg
    sudo apt-get update

    # Remove user configs and certs
    rm -rf ~/.cloudflared

    # Remove system-wide config
    sudo rm -rf /etc/cloudflared

	cloudflared version
